{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (595212, 59)\n",
      "Test shape: (892816, 58)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Oct  5 18:36:22 2017\n",
    "\n",
    "@author: NF299\n",
    "\"\"\"\n",
    "#copy of Kernel https://www.kaggle.com/kueipo/stratifiedshufflesplit-xgboost-example-0-28/code\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "#import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import time\n",
    "\n",
    "# Read in our input data\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "\n",
    "\n",
    "# This prints out (rows, columns) in each dataframe\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n",
    "\n",
    "\n",
    "y = train.target.values\n",
    "id_test = test['id'].values\n",
    "\n",
    "\n",
    "# Define the gini metric - from https://www.kaggle.com/c/ClaimPredictionChallenge/discussion/703#5897\n",
    "def ginic(actual, pred):\n",
    "    actual = np.asarray(actual) #In case, someone passes Series or list\n",
    "    n = len(actual)\n",
    "    a_s = actual[np.argsort(pred)]\n",
    "    a_c = a_s.cumsum()\n",
    "    giniSum = a_c.sum() / a_s.sum() - (n + 1) / 2.0\n",
    "    return giniSum / n\n",
    " \n",
    "def gini_normalized(a, p):\n",
    "    if p.ndim == 2:#Required for sklearn wrapper\n",
    "        p = p[:,1] #If proba array contains proba for both 0 and 1 classes, just pick class 1\n",
    "    return ginic(a, p) / ginic(a, a)\n",
    "\n",
    "# Create an XGBoost-compatible metric from Gini\n",
    "\n",
    "def gini_xgb(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    gini_score = gini_normalized(labels, preds)\n",
    "    return 'gini', gini_score\n",
    "    \n",
    "# We drop these variables as we don't want to train on them\n",
    "# The other 57 columns are all numerical and can be trained on without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (595212, 57)\n",
      "Test shape: (892816, 57)\n",
      "[Fold 1/5]\n",
      "[0]\ttrain-auc:0.602194\tvalid-auc:0.594019\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 70 rounds.\n",
      "[100]\ttrain-auc:0.628884\tvalid-auc:0.624246\n",
      "[200]\ttrain-auc:0.632152\tvalid-auc:0.626378\n",
      "[300]\ttrain-auc:0.637573\tvalid-auc:0.629094\n",
      "[400]\ttrain-auc:0.646463\tvalid-auc:0.634251\n",
      "[500]\ttrain-auc:0.653939\tvalid-auc:0.637862\n",
      "[600]\ttrain-auc:0.660546\tvalid-auc:0.640422\n",
      "[700]\ttrain-auc:0.666705\tvalid-auc:0.642068\n",
      "[800]\ttrain-auc:0.671865\tvalid-auc:0.642501\n",
      "[900]\ttrain-auc:0.676489\tvalid-auc:0.642911\n",
      "[1000]\ttrain-auc:0.680856\tvalid-auc:0.64302\n",
      "Stopping. Best iteration:\n",
      "[979]\ttrain-auc:0.679993\tvalid-auc:0.643069\n",
      "\n",
      "[Fold 1/5 Prediction:]\n",
      "[Fold 2/5]\n",
      "[0]\ttrain-auc:0.601638\tvalid-auc:0.605264\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 70 rounds.\n",
      "[100]\ttrain-auc:0.629704\tvalid-auc:0.622986\n",
      "[200]\ttrain-auc:0.632332\tvalid-auc:0.624349\n",
      "[300]\ttrain-auc:0.63779\tvalid-auc:0.627326\n",
      "[400]\ttrain-auc:0.646181\tvalid-auc:0.63259\n",
      "[500]\ttrain-auc:0.653924\tvalid-auc:0.637153\n",
      "[600]\ttrain-auc:0.660479\tvalid-auc:0.640283\n",
      "[700]\ttrain-auc:0.666271\tvalid-auc:0.642097\n",
      "[800]\ttrain-auc:0.671154\tvalid-auc:0.643339\n",
      "[900]\ttrain-auc:0.675575\tvalid-auc:0.644034\n",
      "[1000]\ttrain-auc:0.679897\tvalid-auc:0.644303\n",
      "[1100]\ttrain-auc:0.683717\tvalid-auc:0.644583\n",
      "[1200]\ttrain-auc:0.687564\tvalid-auc:0.644704\n",
      "[1300]\ttrain-auc:0.691177\tvalid-auc:0.644944\n",
      "Stopping. Best iteration:\n",
      "[1291]\ttrain-auc:0.690912\tvalid-auc:0.644965\n",
      "\n",
      "[Fold 2/5 Prediction:]\n",
      "[Fold 3/5]\n",
      "[0]\ttrain-auc:0.603332\tvalid-auc:0.590648\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 70 rounds.\n",
      "[100]\ttrain-auc:0.630882\tvalid-auc:0.612974\n",
      "[200]\ttrain-auc:0.633154\tvalid-auc:0.614106\n",
      "[300]\ttrain-auc:0.638677\tvalid-auc:0.618311\n",
      "[400]\ttrain-auc:0.647075\tvalid-auc:0.624119\n",
      "[500]\ttrain-auc:0.654471\tvalid-auc:0.628638\n",
      "[600]\ttrain-auc:0.66109\tvalid-auc:0.631982\n",
      "[700]\ttrain-auc:0.667015\tvalid-auc:0.634028\n",
      "[800]\ttrain-auc:0.672283\tvalid-auc:0.635162\n",
      "[900]\ttrain-auc:0.677092\tvalid-auc:0.63589\n",
      "[1000]\ttrain-auc:0.68146\tvalid-auc:0.63632\n",
      "[1100]\ttrain-auc:0.68576\tvalid-auc:0.63651\n",
      "[1200]\ttrain-auc:0.689478\tvalid-auc:0.63681\n",
      "Stopping. Best iteration:\n",
      "[1188]\ttrain-auc:0.689064\tvalid-auc:0.636852\n",
      "\n",
      "[Fold 3/5 Prediction:]\n",
      "[Fold 4/5]\n",
      "[0]\ttrain-auc:0.601226\tvalid-auc:0.602844\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 70 rounds.\n",
      "[100]\ttrain-auc:0.628825\tvalid-auc:0.626351\n",
      "[200]\ttrain-auc:0.63121\tvalid-auc:0.628078\n",
      "[300]\ttrain-auc:0.636237\tvalid-auc:0.631846\n",
      "[400]\ttrain-auc:0.645296\tvalid-auc:0.637229\n",
      "[500]\ttrain-auc:0.653252\tvalid-auc:0.641314\n",
      "[600]\ttrain-auc:0.66013\tvalid-auc:0.644354\n",
      "[700]\ttrain-auc:0.666092\tvalid-auc:0.646096\n",
      "[800]\ttrain-auc:0.671194\tvalid-auc:0.64712\n",
      "[900]\ttrain-auc:0.675728\tvalid-auc:0.64763\n",
      "[1000]\ttrain-auc:0.680057\tvalid-auc:0.647922\n",
      "[1100]\ttrain-auc:0.684042\tvalid-auc:0.648127\n",
      "[1200]\ttrain-auc:0.687886\tvalid-auc:0.648334\n",
      "Stopping. Best iteration:\n",
      "[1143]\ttrain-auc:0.685751\tvalid-auc:0.648345\n",
      "\n",
      "[Fold 4/5 Prediction:]\n",
      "[Fold 5/5]\n",
      "[0]\ttrain-auc:0.600102\tvalid-auc:0.591957\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 70 rounds.\n",
      "[100]\ttrain-auc:0.629558\tvalid-auc:0.620595\n",
      "[200]\ttrain-auc:0.632387\tvalid-auc:0.621814\n",
      "[300]\ttrain-auc:0.63779\tvalid-auc:0.625058\n",
      "[400]\ttrain-auc:0.646815\tvalid-auc:0.62968\n",
      "[500]\ttrain-auc:0.653958\tvalid-auc:0.633097\n",
      "[600]\ttrain-auc:0.660403\tvalid-auc:0.635511\n",
      "[700]\ttrain-auc:0.666065\tvalid-auc:0.637272\n",
      "[800]\ttrain-auc:0.671213\tvalid-auc:0.638261\n",
      "[900]\ttrain-auc:0.675814\tvalid-auc:0.639046\n",
      "[1000]\ttrain-auc:0.680073\tvalid-auc:0.639605\n",
      "[1100]\ttrain-auc:0.683879\tvalid-auc:0.639909\n",
      "[1200]\ttrain-auc:0.68754\tvalid-auc:0.640088\n",
      "[1300]\ttrain-auc:0.691096\tvalid-auc:0.640194\n",
      "[1400]\ttrain-auc:0.694725\tvalid-auc:0.640377\n",
      "Stopping. Best iteration:\n",
      "[1417]\ttrain-auc:0.695354\tvalid-auc:0.64043\n",
      "\n",
      "[Fold 5/5 Prediction:]\n",
      "Elapsed Time = 32084.68171977997\n",
      "Best Score= 0.64043\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "train = train.drop(['id','target'], axis=1)\n",
    "test = test.drop(['id'], axis=1)\n",
    "#ff drop least important features\n",
    "lil_features = ['ps_ind_08_bin', 'ps_ind_09_bin', 'ps_ind_10_bin', 'ps_ind_11_bin',\n",
    "       'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_ind_14', 'ps_ind_18_bin',\n",
    "       'ps_car_02_cat', 'ps_car_08_cat', 'ps_car_10_cat', 'ps_calc_15_bin',\n",
    "       'ps_calc_20_bin']\n",
    "li_features = []\n",
    "train = train.drop(li_features, axis=1)\n",
    "test = test.drop(li_features, axis=1)\n",
    "\n",
    "print('Train shape:', train.shape)\n",
    "print('Test shape:', test.shape)\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "imr = Imputer(missing_values=-1, strategy='mean', axis=0)\n",
    "imr = imr.fit(train.values)\n",
    "\n",
    "\n",
    "#ff X = train.values\n",
    "X = imr.transform(train.values)\n",
    "cleantest = imr.transform(test.values)\n",
    "# Set xgb parameters\n",
    "\n",
    "params = {}\n",
    "params['objective'] = 'binary:logistic'\n",
    "params['eta'] = 0.01\n",
    "params['silent'] = True\n",
    "params['max_depth'] = 5  #ff era 5\n",
    "params['subsample'] = 0.9\n",
    "params['colsample_bytree'] = 0.85\n",
    "params['colsample_bylevel'] = 0.9\n",
    "params['eval_metric'] = 'auc'\n",
    "params['lambda'] = 1\n",
    "#params['tree_method'] = 'exact'\n",
    "\n",
    "# Create a submission file\n",
    "sub = pd.DataFrame()\n",
    "sub['id'] = id_test\n",
    "sub['target'] = np.zeros_like(id_test)\n",
    "\n",
    "# Take a random 30% of the dataset as validation data\n",
    "\n",
    "kfold = 5\n",
    "sss = StratifiedShuffleSplit(n_splits=kfold, test_size=0.15, random_state=42)\n",
    "for i, (train_index, test_index) in enumerate(sss.split(X, y)):\n",
    "    print('[Fold %d/%d]' % (i + 1, kfold))\n",
    "    X_train, X_valid = X[train_index], X[test_index]\n",
    "    y_train, y_valid = y[train_index], y[test_index]\n",
    "    # Convert our data into LGBoost format\n",
    "    d_train = xgb.DMatrix(X_train, y_train)\n",
    "    d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "    d_test = xgb.DMatrix(cleantest)\n",
    "    watchlist = [(d_train, 'train'), (d_valid, 'valid')]\n",
    "\n",
    "    # Train the model! We pass in a max of 2,000 rounds (with early stopping after 100)\n",
    "    # and the custom metric (maximize=True tells xgb that higher metric is better)\n",
    "    mdl = xgb.train(params, d_train, 1600, watchlist, early_stopping_rounds=70, #feval=gini_xgb,\n",
    "                    maximize=True, verbose_eval=100)\n",
    "\n",
    "    print('[Fold %d/%d Prediction:]' % (i + 1, kfold))\n",
    "    # Predict on our test data\n",
    "    p_test = mdl.predict(d_test)\n",
    "    sub['target'] += p_test/kfold\n",
    "\n",
    "\n",
    "\n",
    "# Create a submission file\n",
    "sub.to_csv('StratifiedShuffleSplit.csv', index=False)\n",
    "print('Elapsed Time =', time.time() - start_time)\n",
    "print('Best Score=', mdl.attr('best_score') )\n",
    "#Features importance\n",
    "#mdl.get_fscore()\n",
    "#for i,f in enumerate(train.columns):\n",
    "#    print(i,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
